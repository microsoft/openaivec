{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of spark\n",
    "\n",
    "This notebook demonstrates how to integrate Apache Spark with OpenAI's API to perform token counting, embedding generation, and multilingual translation using Spark UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 23:13:06 WARN Utils: Your hostname, Hirokis-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.12 instead (on interface en0)\n",
      "25/05/05 23:13:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/05 23:13:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Data\n",
    "\n",
    "Create a simple DataFrame containing names of fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with fruit names\n",
    "fruit_data = [(\"apple\",), (\"banana\",), (\"cherry\",), (\"mango\",), (\"orange\",), (\"peach\",), (\"pear\",), (\"pineapple\",), (\"plum\",), (\"strawberry\",)]\n",
    "df = spark.createDataFrame(fruit_data, [\"name\"])\n",
    "df.createOrReplaceTempView(\"fruits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      name|\n",
      "+----------+\n",
      "|     apple|\n",
      "|    banana|\n",
      "|    cherry|\n",
      "|     mango|\n",
      "|    orange|\n",
      "|     peach|\n",
      "|      pear|\n",
      "| pineapple|\n",
      "|      plum|\n",
      "|strawberry|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the fruits DataFrame\n",
    "spark.sql(\"select * from fruits\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Tokens\n",
    "\n",
    "Use OpenAI's GPT model to count the number of tokens in each fruit name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x10b1e1b40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register UDF to count tokens using OpenAI GPT model\n",
    "from openaivec.spark import count_tokens_udf\n",
    "\n",
    "spark.udf.register(\"count_tokens\", count_tokens_udf(\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      name|token_count|\n",
      "+----------+-----------+\n",
      "|     apple|          1|\n",
      "|    banana|          1|\n",
      "|    cherry|          2|\n",
      "|     mango|          2|\n",
      "|    orange|          1|\n",
      "|     peach|          2|\n",
      "|      pear|          1|\n",
      "| pineapple|          2|\n",
      "|      plum|          2|\n",
      "|strawberry|          3|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show token counts for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        count_tokens(name) as token_count\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Generate embeddings for each fruit name using OpenAI's embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x10e2cc4c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register UDF to generate embeddings\n",
    "import os\n",
    "\n",
    "from openaivec.spark import EmbeddingsUDFBuilder\n",
    "\n",
    "embeddings_udf = EmbeddingsUDFBuilder.of_openai(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "spark.udf.register(\"embed\", embeddings_udf.build(batch_size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===============================>                          (6 + 5) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|           embedding|\n",
      "+----------+--------------------+\n",
      "|     apple|[0.01764064, -0.0...|\n",
      "|    banana|[0.013411593, -0....|\n",
      "|    cherry|[0.036218576, -0....|\n",
      "|     mango|[0.055494547, -0....|\n",
      "|    orange|[-0.025922043, -0...|\n",
      "|     peach|[0.030673496, -0....|\n",
      "|      pear|[0.023718908, -0....|\n",
      "| pineapple|[0.020983547, -0....|\n",
      "|      plum|[0.0049052937, 6....|\n",
      "|strawberry|[0.020106195, -0....|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display embeddings for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        embed(name) as embedding\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual Translation\n",
    "\n",
    "Translate fruit names into multiple languages using OpenAI's GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 23:15:38 WARN SimpleFunctionRegistry: The function translate replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x10b203610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register UDF for multilingual translation\n",
    "import os\n",
    "\n",
    "from openaivec.spark import ResponsesUDFBuilder\n",
    "from pydantic import BaseModel\n",
    "\n",
    "udf = ResponsesUDFBuilder.of_openai(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4.1-nano\",\n",
    ")\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    en: str\n",
    "    fr: str\n",
    "    ja: str\n",
    "    es: str\n",
    "    de: str\n",
    "    it: str\n",
    "    pt: str\n",
    "    ru: str\n",
    "\n",
    "spark.udf.register(\"translate\", udf.build(\n",
    "    instructions=\"Translate the following text to English, French, Japanese, Spanish, German, Italian, Portuguese, and Russian.\",\n",
    "    response_format=Translation,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "The model name 'gpt-4.1-nano' is not supported by tiktoken. Instead, using the 'o200k_base' encoding.\n",
      "[Stage 11:==================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "|      name|                      t|        en|    fr|          ja|     es|      de|      it|     pt|      ru|\n",
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "|     apple| {apple, pomme, リン...|     apple| pomme|      リンゴ|manzana|   Apfel|    mela|   maçã|  яблоко|\n",
      "|    banana|   {banana, banane, ...|    banana|banane|      バナナ|plátano|  Banane|  banana| banana|   банан|\n",
      "|    cherry|   {cherry, cerise, ...|    cherry|cerise|  さくらんぼ| cereza| Kirsche|ciliegia| cereja|   вишня|\n",
      "|     mango|  {mango, mangue, マ...|     mango|mangue|    マンゴー|  mango|   Mango|   mango|  manga|   манго|\n",
      "|    orange|   {orange, orange, ...|    orange|orange|    オレンジ|naranja|  orange| arancia|laranja|апельсин|\n",
      "|     peach| {peach, pêche, もも...|     peach| pêche|        もも|durazno|Pfirsich|   pesca|pêssego|  персик|\n",
      "|      pear|  {pear, poire, 梨, ...|      pear| poire|          梨|   pera|   Birne|    pera|   pêra|   груша|\n",
      "| pineapple|   {pineapple, anana...| pineapple|ananas|パイナップル|   piña|  Ananas|  ananas|abacaxi|  ананас|\n",
      "|      plum|{plum, prune, プラム...|      plum| prune|      プラム|ciruela| Pflaume|  prugna| ameixa|   слива|\n",
      "|strawberry|   {strawberry, frai...|strawberry|fraise|      イチゴ|  fresa|Erdbeere| fragola|morango|клубника|\n",
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display translations for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        translate(name) as t,\n",
    "        t.en as en,\n",
    "        t.fr as fr,\n",
    "        t.ja as ja,\n",
    "        t.es as es,\n",
    "        t.de as de,\n",
    "        t.it as it,\n",
    "        t.pt as pt,\n",
    "        t.ru as ru\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook illustrated how to effectively integrate Apache Spark with OpenAI's API for various NLP tasks such as token counting, embedding generation, and multilingual translation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
