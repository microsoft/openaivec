{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Basics\n",
    "\n",
    "This notebook explains Spark usage in order: main input, generated outputs, and practical benefits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Initialize Spark and configure OpenAI authentication once. If built-in `%%sql` is unavailable, this notebook registers a compatible fallback backed by `spark.sql`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython import get_ipython\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from openaivec.spark import responses_udf, setup, task_udf\n",
    "from openaivec.task import nlp\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"Set OPENAI_API_KEY before running this notebook.\")\n",
    "\n",
    "setup(spark, api_key=api_key)\n",
    "\n",
    "ip = get_ipython()\n",
    "if ip and \"sql\" not in ip.magics_manager.magics[\"cell\"]:\n",
    "    def _spark_sql_magic(line: str, cell: str):\n",
    "        return spark.sql(cell).show(truncate=False)\n",
    "\n",
    "    ip.register_magic_function(_spark_sql_magic, \"cell\", \"sql\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input: Spark DataFrame\n",
    "\n",
    "Prepare a DataFrame of fruit names. This is the main input to Spark UDFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = spark.createDataFrame(\n",
    "    [(\"apple\",), (\"banana\",), (\"lemon\",), (\"grapefruit\",)],\n",
    "    [\"name\"],\n",
    ")\n",
    "fruits.createOrReplaceTempView(\"fruits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|name      |\n",
      "+----------+\n",
      "|apple     |\n",
      "|banana    |\n",
      "|lemon     |\n",
      "|grapefruit|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT name\n",
    "FROM fruits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Output A: plain-text response column\n",
    "\n",
    "Use `responses_udf` to generate one short text output per row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x118592a10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\n",
    "    \"describe_fruit\",\n",
    "    responses_udf(\n",
    "        instructions=\"Describe the fruit in one short sentence.\",\n",
    "        batch_size=64,\n",
    "        max_concurrency=4,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:04<00:00,  4.98s/item] (3 + 1) / 4]\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/item](8 + 3) / 11]\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.25s/item](9 + 2) / 11]\n",
      "[Stage 5:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------------------------------------------------+\n",
      "|name      |description                                                                        |\n",
      "+----------+-----------------------------------------------------------------------------------+\n",
      "|apple     |An apple is a round fruit with red, green, or yellow skin and a sweet, crisp flesh.|\n",
      "|banana    |A banana is a long, curved yellow fruit with soft, sweet flesh.                    |\n",
      "|lemon     |A lemon is a yellow citrus fruit known for its sour taste.                         |\n",
      "|grapefruit|Grapefruit is a large citrus fruit with a tangy and slightly bitter taste.         |\n",
      "+----------+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.91s/item]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    name,\n",
    "    describe_fruit(name) AS description\n",
    "FROM fruits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output B: structured task column\n",
    "\n",
    "Use a predefined task to return typed fields with a stable schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x118593d60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\n",
    "    \"analyze_sentiment\",\n",
    "    task_udf(\n",
    "        nlp.sentiment_analysis(),\n",
    "        batch_size=64,\n",
    "        max_concurrency=4,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/item] (3 + 1) / 4]\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/item](8 + 3) / 11]\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.73s/item](9 + 2) / 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n",
      "|name      |sentiment|confidence|\n",
      "+----------+---------+----------+\n",
      "|apple     |neutral  |0.95      |\n",
      "|banana    |neutral  |0.99      |\n",
      "|lemon     |neutral  |0.99      |\n",
      "|grapefruit|neutral  |0.99      |\n",
      "+----------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.89s/item]10 + 1) / 11]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "WITH analyzed AS (\n",
    "    SELECT\n",
    "        name,\n",
    "        analyze_sentiment(name) AS result\n",
    "    FROM fruits\n",
    ")\n",
    "SELECT\n",
    "    name,\n",
    "    result.sentiment AS sentiment,\n",
    "    result.confidence AS confidence\n",
    "FROM analyzed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Benefits\n",
    "\n",
    "**Main input**\n",
    "- Spark DataFrame columns\n",
    "- UDF instructions or predefined tasks\n",
    "\n",
    "**Main output**\n",
    "- New plain-text columns (`responses_udf`)\n",
    "- New structured columns (`task_udf`)\n",
    "\n",
    "**Why this helps**\n",
    "- Keeps Spark pipelines while adding LLM processing\n",
    "- Preserves schema for downstream SQL/DataFrame logic\n",
    "- Scales with `batch_size` and `max_concurrency` tuning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivec (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
