{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of spark\n",
    "\n",
    "This notebook demonstrates how to integrate Apache Spark with OpenAI's API to perform token counting, embedding generation, and multilingual translation using Spark UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize Spark session\nimport os\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext\nsc.environment[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Data\n",
    "\n",
    "Create a simple DataFrame containing names of fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with fruit names\n",
    "fruit_data = [(\"apple\",), (\"banana\",), (\"cherry\",), (\"mango\",), (\"orange\",), (\"peach\",), (\"pear\",), (\"pineapple\",), (\"plum\",), (\"strawberry\",)]\n",
    "df = spark.createDataFrame(fruit_data, [\"name\"])\n",
    "df.createOrReplaceTempView(\"fruits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      name|\n",
      "+----------+\n",
      "|     apple|\n",
      "|    banana|\n",
      "|    cherry|\n",
      "|     mango|\n",
      "|    orange|\n",
      "|     peach|\n",
      "|      pear|\n",
      "| pineapple|\n",
      "|      plum|\n",
      "|strawberry|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display the fruits DataFrame\n",
    "spark.sql(\"select * from fruits\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Tokens\n",
    "\n",
    "Use OpenAI's GPT model to count the number of tokens in each fruit name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Register UDF to count tokens using OpenAI GPT model\nfrom openaivec.spark import count_tokens_udf\n\nspark.udf.register(\"count_tokens\", count_tokens_udf())"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      name|token_count|\n",
      "+----------+-----------+\n",
      "|     apple|          1|\n",
      "|    banana|          1|\n",
      "|    cherry|          2|\n",
      "|     mango|          2|\n",
      "|    orange|          1|\n",
      "|     peach|          2|\n",
      "|      pear|          1|\n",
      "| pineapple|          2|\n",
      "|      plum|          2|\n",
      "|strawberry|          3|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show token counts for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        count_tokens(name) as token_count\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Generate embeddings for each fruit name using OpenAI's embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Register UDF to generate embeddings\nimport os\n\nfrom openaivec.spark import embeddings_udf\n\nspark.udf.register(\"embed\", embeddings_udf(model_name=\"text-embedding-3-small\", batch_size=1024))"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|           embedding|\n",
      "+----------+--------------------+\n",
      "|     apple|[0.01763439, -0.0...|\n",
      "|    banana|[0.013411593, -0....|\n",
      "|    cherry|[0.036222804, -0....|\n",
      "|     mango|[0.055474974, -0....|\n",
      "|    orange|[-0.025922043, -0...|\n",
      "|     peach|[0.030673496, -0....|\n",
      "|      pear|[0.023664422, -0....|\n",
      "| pineapple|[0.020983547, -0....|\n",
      "|      plum|[0.0049052937, 6....|\n",
      "|strawberry|[0.020106195, -0....|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display embeddings for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        embed(name) as embedding\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual Translation\n",
    "\n",
    "Translate fruit names into multiple languages using OpenAI's GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Register UDF for multilingual translation\nimport os\n\nfrom pydantic import BaseModel\n\nfrom openaivec.spark import responses_udf\n\nclass Translation(BaseModel):\n    en: str\n    fr: str\n    ja: str\n    es: str\n    de: str\n    it: str\n    pt: str\n    ru: str\n\nspark.udf.register(\"translate\", responses_udf(\n    instructions=\"Translate the following text to English, French, Japanese, Spanish, German, Italian, Portuguese, and Russian.\",\n    response_format=Translation,\n    model_name=\"gpt-4.1-nano\"\n))"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:==============================================>          (9 + 2) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "|      name|                      t|        en|    fr|          ja|     es|      de|      it|     pt|      ru|\n",
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "|     apple| {apple, pomme, リン...|     apple| pomme|      リンゴ|manzana|   Apfel|    mela|   maçã|  яблоко|\n",
      "|    banana|   {banana, banane, ...|    banana|banane|      バナナ|plátano|  Banane|  banana| banana|   банан|\n",
      "|    cherry|   {cherry, cerise, ...|    cherry|cerise|  さくらんぼ| cereza| Kirsche|ciliegia| cereja|   вишня|\n",
      "|     mango|  {mango, mangue, マ...|     mango|mangue|    マンゴー|  mango|   Mango|   mango|  manga|   манго|\n",
      "|    orange|   {orange, orange, ...|    orange|orange|    オレンジ|naranja|  Orange| arancia|laranja|апельсин|\n",
      "|     peach| {peach, pêche, もも...|     peach| pêche|        もも|durazno|Pfirsich|   pesca|pêssego|  персик|\n",
      "|      pear|  {pear, poire, 梨, ...|      pear| poire|          梨|   pera|   Birne|    pera|   pêra|   груша|\n",
      "| pineapple|   {Pineapple, Anana...| Pineapple|Ananas|パイナップル|   Piña|  Ananas|  Ananas|Abacaxi|  Ананас|\n",
      "|      plum|{plum, prune, プラム...|      plum| prune|      プラム|ciruela| Pflaume|  prugna| ameixa|   слива|\n",
      "|strawberry|   {strawberry, frai...|strawberry|fraise|      イチゴ|  fresa|Erdbeere| fragola|morango|клубника|\n",
      "+----------+-----------------------+----------+------+------------+-------+--------+--------+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display translations for each fruit name\n",
    "spark.sql(\"\"\"\n",
    "    select\n",
    "        name,\n",
    "        translate(name) as t,\n",
    "        t.en as en,\n",
    "        t.fr as fr,\n",
    "        t.ja as ja,\n",
    "        t.es as es,\n",
    "        t.de as de,\n",
    "        t.it as it,\n",
    "        t.pt as pt,\n",
    "        t.ru as ru\n",
    "    from fruits\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook illustrated how to effectively integrate Apache Spark with OpenAI's API for various NLP tasks such as token counting, embedding generation, and multilingual translation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaivec (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}